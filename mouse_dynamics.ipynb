{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZenMachina16/MLP-implentation/blob/main/mouse_dynamics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RCdVMLR45YB"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4rwC7fo5i6U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import seaborn as sn\n",
        "import hashlib\n",
        "import binascii\n",
        "import math\n",
        "from sklearn.decomposition import PCA as skPCA\n",
        "from pyspark.ml.feature import PCA as spPCA\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.tuning import CrossValidator, TrainValidationSplit, ParamGridBuilder, TrainValidationSplitModel\n",
        "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier, GBTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.types import StructType, StringType, FloatType, LongType, IntegerType, StructField\n",
        "from pyspark.sql import HiveContext, SparkSession\n",
        "from pyspark.sql.functions import countDistinct, array_distinct, col, isnan, when, count, lit, array\n",
        "\n",
        "plt.rcParams[\"figure.autolayout\"] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzfyW-E35xsy"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_zvjl-S6HQc"
      },
      "outputs": [],
      "source": [
        "schemaMousePos = StructType([\n",
        "    StructField('uid', StringType(), False,),\n",
        "    StructField('session_id', StringType(), False),\n",
        "    StructField('user_id', StringType(), True),\n",
        "    StructField('timestamp', LongType(), False),\n",
        "    StructField('event_type', IntegerType(), False),\n",
        "    StructField('screen_x', FloatType(), False),\n",
        "    StructField('screen_y', FloatType(), False)\n",
        "])\n",
        "trainDs = spark.read.csv('/content/Train_Mouse.csv',header=True, schema=schemaMousePos)\n",
        "trainDs.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HbSd-sq6O7K"
      },
      "outputs": [],
      "source": [
        "trainDs.groupBy('session_id').agg(countDistinct('user_id').alias('distinct_uids_per_session')).agg({'distinct_uids_per_session':'max'}).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeMtqRXY6WhZ"
      },
      "outputs": [],
      "source": [
        "trainDs.groupBy('user_id').agg(countDistinct('session_id')).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0cm_2eG6W8N"
      },
      "outputs": [],
      "source": [
        "trainDs.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in trainDs.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK7n3Yzw6hS1"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
        "eventMap = {1:'release', 2:'move', 3 : 'wheel', 4:'drag', 5 : 'click'}\n",
        "# set colormap\n",
        "colorsRevDict = {'#'+hashlib.md5((('{}-{}'.format(i, j))*16).encode()).hexdigest()[:6] : '{} -> {}'.format(eventMap[i],eventMap[j])  for i in range(1,6) for j in range(1,6)}\n",
        "soa = np.array([[0,i,1,j-i] for i in range(1,6) for j in range(1,6)])\n",
        "X, Y, U, V = zip(*soa)\n",
        "plt.figure()\n",
        "ax = plt.gca()\n",
        "# generate unique color for each transition,\n",
        "colors = ['#'+hashlib.md5((('{}-{}'.format(i, j))*16).encode()).hexdigest()[:6] for i in range(1,6) for j in range(1,6)]\n",
        "ax.quiver(X, Y, U, V, angles='xy', scale_units='xy', scale=1, color=colors, linewidth=0.3)\n",
        "ax.set_xlim([-1,2])\n",
        "ax.set_ylim([0,6])\n",
        "plt.draw()\n",
        "plt.show()\n",
        "print(eventMap)\n",
        "print(colorsRevDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LQeSdK9c7-CD"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [30, 15]\n",
        "df = trainDs.toPandas().sort_values('timestamp')\n",
        "# usersEncoder will simplify user_id strings into a small range values\n",
        "usersEncoder = {k:i for i,k in enumerate(trainDs.select('user_id').rdd.flatMap(lambda x: x).distinct().collect())}\n",
        "screenDims = ((df['screen_x'].min(),df['screen_x'].max()), (df['screen_y'].min(),df['screen_y'].max()))\n",
        "for userId in usersEncoder.keys(): # df['user_id'].unique():\n",
        "    portionDf = df[df['user_id']==userId]\n",
        "    print(usersEncoder[userId], userId)\n",
        "    for session in portionDf['session_id'].unique():\n",
        "        portionDfSession = portionDf[portionDf['session_id']==session]\n",
        "        XYs = np.array([(k[1].screen_x, k[1].screen_y) for k in portionDfSession.iterrows()]).astype(float) # xy\n",
        "        evs = [k[1].event_type for k in portionDfSession.iterrows()] # events\n",
        "        tss = [int(k[1].timestamp) for k in portionDfSession.iterrows()] # timestamps\n",
        "        soa = np.array([[XYs[i][0],XYs[i][1], XYs[i+1][0]-XYs[i][0],XYs[i+1][1]-XYs[i][1]] for i in range(len(XYs)-1)])\n",
        "        tsd = np.array([tss[i+1]-tss[i] for i in range(len(tss)-1)]).astype(int)\n",
        "\n",
        "        X, Y, U, V = zip(*soa)\n",
        "        plt.figure()\n",
        "        ax = plt.gca()\n",
        "        colors = ['#'+hashlib.md5((('{}-{}'.format(evs[i], evs[i+1]))*16).encode()).hexdigest()[:6] for i in range(len(evs)-1)]\n",
        "        q = ax.quiver(X, Y, U, V, angles='xy', scale_units='xy', scale=1, color=colors, width=0.001) #, label=colors)\n",
        "        ax.set_xlim([screenDims[0][0]-100,screenDims[0][1]+100])\n",
        "        ax.set_ylim([screenDims[1][0]-100,screenDims[1][1]+100])\n",
        "        custom_lines = [Line2D([0], [0], color=c, lw=4) for c in set(colors)]\n",
        "        ax.legend(custom_lines, [colorsRevDict[c] for c in set(colors)])\n",
        "\n",
        "        plt.draw()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5eTR0B-a9Bqv"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [30, 15]\n",
        "for userId in usersEncoder.keys():\n",
        "    portionDf = df[df['user_id']==userId]\n",
        "    print(usersEncoder[userId], userId)\n",
        "    for session in portionDf['session_id'].unique():\n",
        "        portionDfSession = portionDf[portionDf['session_id']==session]\n",
        "        evs = [int(k[1].event_type) for k in portionDfSession.iterrows()] # events\n",
        "        tss = [int(k[1].timestamp) for k in portionDfSession.iterrows()]\n",
        "        # let's plt also the LogLog since, well, some users enjoy taking long breaks..\n",
        "        tss1 = [math.log(math.log(10000+int(k)-tss[0])) for k in tss]\n",
        "        f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
        "        ax1.plot(tss,evs) # base\n",
        "        ax2.plot(tss1,evs) # loglog\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l57JpaYq6rPr"
      },
      "outputs": [],
      "source": [
        "schemaFeatures = StructType([\n",
        "    StructField('session_id', StringType(), False),\n",
        "    StructField('user_id', StringType(), True),\n",
        "    StructField('user_enc', FloatType(), True),\n",
        "    StructField('center_x', FloatType(), False),\n",
        "    StructField('center_y', FloatType(), False),\n",
        "    StructField('center_click_x', FloatType(), False),\n",
        "    StructField('center_click_y', FloatType(), False),\n",
        "    StructField('first_x', FloatType(), False),\n",
        "    StructField('first_y', FloatType(), False),\n",
        "    StructField('radius', FloatType(), False),\n",
        "    StructField('slope', FloatType(), False),\n",
        "    StructField('narrow', FloatType(), False),\n",
        "    StructField('ev1', FloatType(), False),\n",
        "    StructField('ev2', FloatType(), False),\n",
        "    StructField('ev3', FloatType(), False),\n",
        "    StructField('ev4', FloatType(), False),\n",
        "    StructField('ev5', FloatType(), False),\n",
        "    StructField('stress', IntegerType(), False),\n",
        "    StructField('chill', IntegerType(), False),\n",
        "    StructField('nbpoints', IntegerType(), False),\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S9VbMCS47Fx7"
      },
      "outputs": [],
      "source": [
        "def featurize(recordsIn):\n",
        "    session_id, user_id = recordsIn[0]\n",
        "    records = recordsIn[1]\n",
        "\n",
        "    center = (lambda axisList: sum(axisList)/len(axisList))\n",
        "    maxRadius = (lambda xc,yc,xList,yList: max([math.sqrt((xi-xc)**2+(yi-yc)**2) for xi, yi in zip(xList,yList)]))\n",
        "    eventRatio = (lambda evKey, allEvents: len([1 for e in allEvents if e==evKey])/len(allEvents))\n",
        "\n",
        "    # to be more precise, min/max duration of inter-events\n",
        "    minSpeed = (lambda timestamps: min([timestamps[i+1]-timestamps[i] for i in range(len(timestamps)-1)]))\n",
        "    maxSpeed = (lambda timestamps: max([timestamps[i+1]-timestamps[i] for i in range(len(timestamps)-1)]))\n",
        "\n",
        "    def slope(xList, yList): # the overall curve direction\n",
        "        x_avg = sum(xList)/len(xList)\n",
        "        y_avg = sum(xList)/len(yList)\n",
        "        u=sum([(xi-x_avg)*(yi-y_avg) for xi, yi in zip(xList,yList)])\n",
        "        d=sum([(xi-x_avg)**2 for xi in xList])\n",
        "        return u/d\n",
        "\n",
        "    def narrow_spark(xList, yList):\n",
        "        spark = SparkSession.builder.getOrCreate()\n",
        "        data = [(Vectors.dense([xi,yi]),) for xi, yi in zip(xList, yList)]\n",
        "        df = spark.createDataFrame(data,[\"features\"])\n",
        "        pca = spPCA(k=1, inputCol=\"features\")\n",
        "        model = pca.fit(df)\n",
        "        return model.explainedVariance[0]\n",
        "\n",
        "    def narrow_sklearn(xList, yList): # determine how compact is the curve, like is it line or cube shaped\n",
        "        X = np.array([[xi,yi] for xi, yi in zip(xList, yList)])\n",
        "        pca = skPCA(n_components=1)\n",
        "        pca.fit(X)\n",
        "        return pca.explained_variance_ratio_[0]\n",
        "\n",
        "    xList = [record['screen_x'] for record in records]\n",
        "    yList = [record['screen_y'] for record in records]\n",
        "    # barycenter of all mouse registered positions\n",
        "    centerX = center(xList)\n",
        "    centerY = center(yList)\n",
        "\n",
        "    # clicks come with interesting spots. let's use their 'barycenter'\n",
        "    centerClickX = center((lambda x: x if x else [0])([record['screen_x'] for record in records if record['event_type']==5]))\n",
        "    centerClickY = center((lambda x: x if x else [0])([record['screen_y'] for record in records if record['event_type']==5]))\n",
        "\n",
        "    # The first move is always precious! it reflects the unconscious mind of the user once holds the mouse\n",
        "    firstX = xList[0]\n",
        "    firstY = yList[0]\n",
        "\n",
        "    # how much space the user takes from the screen (as if we'll put all points inside an imaginary circle)\n",
        "    tangentCircleRadius = maxRadius(centerX,centerY,xList,yList)\n",
        "\n",
        "    # curve curvature\n",
        "    slop = slope(xList, yList)\n",
        "    nar = float(narrow_sklearn(xList, yList))\n",
        "\n",
        "    allEvents = [record['event_type'] for record in records]\n",
        "    # frequency of each event\n",
        "    ev1,ev2,ev3,ev4,ev5 = [eventRatio(i, allEvents) for i in range(1,6)]\n",
        "    # how relaxed is the user\n",
        "    stress = minSpeed(sorted([record['timestamp'] for record in records if record['event_type']==2]))\n",
        "    chill = maxSpeed(sorted([record['timestamp'] for record in records if record['event_type']==2])) # maybe we need to apply log here, since some users take long breaks..\n",
        "    # some users use the mouse more often than others\n",
        "    nbpoints = len(xList)\n",
        "\n",
        "    # TODO: maybe we will need to add more temporal features later, like time center of actions, speed, acceleration, etc.\n",
        "\n",
        "    if user_id:\n",
        "        userEnc = float(usersEncoder[user_id])\n",
        "    else:\n",
        "        userEnc = None # will not be used since it's to be predicted\n",
        "    return session_id, user_id, userEnc, centerX, centerY, centerClickX, centerClickY, firstX, firstY, tangentCircleRadius, slop, nar, ev1, ev2, ev3, ev4, ev5, stress, chill, nbpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zNiP7zSw94T5"
      },
      "outputs": [],
      "source": [
        "featuresDataframe = spark.createDataFrame(\n",
        "    trainDs.rdd.groupBy(lambda x: (x['session_id'], x['user_id'])).map(featurize), schema=schemaFeatures\n",
        ")\n",
        "featuresDataframe.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DpYdRnJk999V"
      },
      "outputs": [],
      "source": [
        "df_featued = featuresDataframe.toPandas()\n",
        "for userId in usersEncoder.keys():\n",
        "    portionDf = df_featued[df_featued['user_id']==userId]\n",
        "    for session in portionDf['session_id'].unique():\n",
        "        portionDfSession = portionDf[portionDf['session_id']==session]\n",
        "        plt.scatter([1,2,3,4,5],portionDfSession[['ev1','ev2','ev3','ev4','ev5']])\n",
        "    print(usersEncoder[userId], userId)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hQY71L07xgm2"
      },
      "outputs": [],
      "source": [
        "# we compose our features vector column\n",
        "in_col = ['center_x', 'center_y', 'center_click_x', 'center_click_y', 'first_x', 'first_y', 'radius', 'slope', 'narrow', 'ev1', 'ev2', 'ev3', 'ev4', 'ev5', 'stress', 'chill', 'nbpoints']\n",
        "nbusers = featuresDataframe.select('user_enc').distinct().count()\n",
        "assemble = VectorAssembler(inputCols=in_col, outputCol='assembled_features', handleInvalid='error')\n",
        "a_data = assemble.transform(featuresDataframe)\n",
        "scaler = MinMaxScaler(min=0.0, max=1.0, inputCol='assembled_features', outputCol='features')\n",
        "fittedScaler = scaler.fit(a_data)\n",
        "s_data = fittedScaler.transform(a_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVJkvqF5z3ZC",
        "outputId": "07e1dfe4-b77f-40f1-9265-5071b49b8484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "# train-test split.\n",
        "train_df,test_df = s_data.select('user_enc','features').randomSplit([0.80,0.20],89)\n",
        "print(train_df.select('user_enc').distinct().count())\n",
        "print(test_df.select('user_enc').distinct().count())\n",
        "mlpc=MultilayerPerceptronClassifier( featuresCol='features',labelCol='user_enc',layers = [len(in_col),40,nbusers],maxIter=30000,blockSize=8,seed=7,solver='gd')\n",
        "ann = mlpc.fit(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "53K3yyc2z36y"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol='user_enc',predictionCol='prediction',metricName='f1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YkNURKsv7UAM"
      },
      "outputs": [],
      "source": [
        "def pltConfusion(pred):\n",
        "    array = np.zeros((nbusers,nbusers), int)\n",
        "    for k in pred.collect():\n",
        "        array[int(k['user_enc']),int(k['prediction'])] = array[int(k['user_enc']),int(k['prediction'])]+1\n",
        "    df_cm = pd.DataFrame(array, range(nbusers), range(nbusers))\n",
        "    plt.figure(figsize=(10,7))\n",
        "    sn.set(font_scale=1.4)\n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIcp0N8L9Tn0"
      },
      "outputs": [],
      "source": [
        "pred = ann.transform(train_df)\n",
        "ann_f1 = evaluator.evaluate(pred)\n",
        "print('Train F1 =', ann_f1)\n",
        "pltConfusion(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1QeDutc9dQO"
      },
      "outputs": [],
      "source": [
        "pred = ann.transform(test_df)\n",
        "ann_f1 = evaluator.evaluate(pred)\n",
        "print('Test F1 =', ann_f1)\n",
        "pltConfusion(pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtVGYCxlv/MfpKuPzGKfGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}